---
---

@misc{Schiekiera2024,
  author = {Schiekiera, L. and Niemeyer, H. and Diederichs, J.},
  title = {Natural Language Processing for Publication Bias Research - Using Machine Learning to Study Positive Results in Clinical Psychology Research Abstracts},
  year = {2024},
  month = {January 9},
  howpublished = {Preprint},
  url = {https://doi.org/10.31234/osf.io/uxyzh},
  preview={scibert_and_rf.png},
  pdf={Schiekiera_et_al_2024_Preprint_Natural_Language_Processing_for_Publication_Bias_Research.pdf},
  abstract = {This study addresses the gap in machine learning tools for publication bias research by evaluating the performance of SciBERT and random forest in classifying results in clinical psychology abstracts. Over 1,900 abstracts were annotated into two categories: ‘positive results only’ and ‘mixed or negative results’. Model performance was evaluated on three benchmarks. The best-performing model was utilized to analyze trends in over 20,000 psychotherapy study abstracts. Results: SciBERT outperformed all benchmarks and random forest in in-domain (accuracy: 0.86) and out-of-domain data (accuracy: 0.85-0.88). The trend analysis revealed non-significant effects of publication year on positive results for 1990-2005, but a significant decrease in positive results between 2005-2022. When examining the entire time-span, significant positive linear and negative quadratic effects were observed. Discussion: Machine learning could support future efforts to address publication bias by identifying negative results in large data sets. The fine-tuned SciBERT model was deployed for public use.}
}

